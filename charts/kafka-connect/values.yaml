# Kafka Connect configuration - fully templated
replicaCount: {{ .Values.global.kafkaConnect.replicas | default 1 }}

image:
  repository: {{ .Values.global.kafkaConnect.image.repository | default "confluentinc/cp-kafka-connect" }}
  tag: {{ .Values.global.kafkaConnect.image.tag | default "7.5.0" }}
  pullPolicy: {{ .Values.global.images.pullPolicy }}

service:
  type: {{ .Values.global.kafkaConnect.service.type | default "ClusterIP" }}
  port: {{ .Values.global.kafkaConnect.service.port | default 8083 }}

# Environment variables templated
env:
  CONNECT_BOOTSTRAP_SERVERS: {{ .Values.global.kafka.bootstrapServers | quote }}
  CONNECT_REST_PORT: {{ .Values.global.kafkaConnect.service.port | default 8083 | quote }}
  CONNECT_GROUP_ID: {{ .Values.global.kafkaConnect.groupId | default "td-pipeline-connect" | quote }}
  CONNECT_CONFIG_STORAGE_TOPIC: {{ .Values.global.kafkaConnect.topics.config | default "connect-config" | quote }}
  CONNECT_OFFSET_STORAGE_TOPIC: {{ .Values.global.kafkaConnect.topics.offset | default "connect-offsets" | quote }}
  CONNECT_STATUS_STORAGE_TOPIC: {{ .Values.global.kafkaConnect.topics.status | default "connect-status" | quote }}
  CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
  CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
  CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
  CONNECT_LOG4J_ROOT_LOGLEVEL: {{ .Values.global.kafkaConnect.logLevel | default "INFO" | quote }}
  CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
  CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: {{ .Values.global.kafkaConnect.replication.config | default 1 | quote }}
  CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: {{ .Values.global.kafkaConnect.replication.offset | default 1 | quote }}
  CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: {{ .Values.global.kafkaConnect.replication.status | default 1 | quote }}

# AWS S3 Sink Connector configuration
connectors:
  s3Sink:
    enabled: {{ .Values.global.kafkaConnect.connectors.s3Sink.enabled | default true }}
    config:
      connector.class: "io.confluent.connect.s3.S3SinkConnector"
      tasks.max: {{ .Values.global.kafkaConnect.connectors.s3Sink.tasksMax | default 1 | quote }}
      topics: {{ .Values.global.kafkaConnect.connectors.s3Sink.topics | default "postgres.public.customers" | quote }}
      s3.bucket.name: {{ .Values.global.s3.bucket | quote }}
      s3.region: {{ .Values.global.aws.region | quote }}
      format.class: "io.confluent.connect.s3.format.parquet.ParquetFormat"
      storage.class: "io.confluent.connect.s3.storage.S3Storage"
      partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
      path.format: "'year'=YYYY/'month'=MM/'day'=dd/'hour'=HH"
      timezone: "UTC"
      flush.size: {{ .Values.global.kafkaConnect.connectors.s3Sink.flushSize | default 1000 | quote }}
      rotate.interval.ms: {{ .Values.global.kafkaConnect.connectors.s3Sink.rotateInterval | default 30000 | quote }}
      schema.compatibility: "NONE"
      
  debezium:
    enabled: {{ .Values.global.kafkaConnect.connectors.debezium.enabled | default true }}
    config:
      connector.class: "io.debezium.connector.postgresql.PostgresConnector"
      tasks.max: {{ .Values.global.kafkaConnect.connectors.debezium.tasksMax | default 1 | quote }}
      database.hostname: {{ .Values.global.database.host | quote }}
      database.port: {{ .Values.global.database.port | quote }}
      database.user: "{{ .Values.global.database.username }}"
      database.password: "{{ .Values.global.database.password }}"
      database.dbname: {{ .Values.global.database.name | quote }}
      database.server.name: {{ .Values.global.kafkaConnect.connectors.debezium.serverName | default "postgres" | quote }}
      table.include.list: {{ .Values.global.kafkaConnect.connectors.debezium.tableIncludeList | default "public.customers" | quote }}
      plugin.name: "pgoutput"
      slot.name: {{ .Values.global.kafkaConnect.connectors.debezium.slotName | default "debezium_slot" | quote }}
      publication.autocreate.mode: "filtered"

resources: {{ .Values.global.kafkaConnect.resources | default .Values.global.resources.medium | toYaml | nindent 2 }}

# Security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
